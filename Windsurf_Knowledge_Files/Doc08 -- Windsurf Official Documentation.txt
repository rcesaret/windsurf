---
file: `Doc10 -- Windsurf Official Documentation.md`
title: "Windsurf Official Documentation"
document_id: "0a1b2c3d-4e5f-6a7b-8c9d-0123456789ab" # Generated UUID
version: "VALUE_NOT_FOUND_IN_DOCUMENT" # No single version for the entire documentation dump
date_created: "VALUE_NOT_FOUND_IN_DOCUMENT" # Original creation dates of sections vary
date_modified: "2025-05-30" # Using processing date as proxy, though specific sections have earlier 'last updated' dates
language: "en"
abstract: |
  A comprehensive collection of official Windsurf documentation covering its AI assistant Cascade (including features, plans, credit usage, app deploys, image upload, web/docs search, memories, rules, workflows, and MCP integration). It also details common Windsurf use cases (code generation, unit tests, commentary, API docs, refactoring), context awareness mechanisms (local indexing, .codeiumignore), security reporting, troubleshooting, Windsurf Editor features (models, Tab, Command, Code Lenses, Smart Paste, Terminal integration, Previews, AI Commit Messages, Advanced Configuration like SSH and Dev Containers), and prompt engineering best practices for Windsurf.
keywords:
  - "Windsurf"
  - "Cascade AI"
  - "Documentation"
  - "User Manual"
  - "Reference Guide"
  - "AI IDE"
  - "Codeium"
  - "MCP Integration"
  - "Memories"
  - "Rules"
  - "Workflows"
  - "Context Awareness"
  - "Local Indexing"
  - "Windsurf Tab"
  - "Windsurf Command"
  - "App Deploys"
  - "Prompt Engineering"
  - "Security"
  - "Troubleshooting"
  - "Credit Usage"
  - "SSH Support"
  - "Dev Containers"
document_type: "Official Documentation" # [cite: 68]
purpose_statement: |
  To serve as the official user guide and comprehensive reference for all features, functionalities, and best practices related to the Windsurf AI IDE and its Cascade assistant.
intended_audience:
  - "Windsurf Users (All Levels)"
  - "Software Developers"
  - "AI Practitioners"
  - "Prospective Windsurf Users"
scope: |
  Covers all aspects of the Windsurf AI IDE and Cascade assistant. Key areas include: Cascade features (model selection, modes, tools, package management, reverting changes, real-time awareness, linter integration, sharing, simultaneous instances), plans and credit usage, app deployment (Netlify, security, rate limits, supported frameworks), image upload, web/docs search, Cascade memories (rules: global, workspace, activation modes, best practices), workflows, MCP integration (adding plugins, mcp_config.json), common use cases (code/test generation, commentary, refactoring), context awareness (default sources, knowledge base, local indexing, .codeiumignore), security policies, troubleshooting, Windsurf Editor features (models, Tab, Command, Code Lenses, Smart Paste, Terminal, Previews, AI Commits, SSH, Dev Containers, WSL, marketplace config), and prompt engineering.
document_status: "Published" # Official documentation
categories: # [cite: 5, 114]
  - "Software Development/Developer Tools"
  - "Artificial Intelligence/AI-Assisted Development"
  - "Technical Documentation/Official Documentation"
tags: # [cite: 6, 133, 136]
  - "Windsurf"
  - "Cascade AI"
  - "Documentation"
  - "User Guide"
  - "Reference"
  - "AI IDE"
  - "Codeium"
  - "MCP"
  - "Rules"
  - "Memories"
  - "Workflows"
  - "Context Awareness"
  - "Windsurf Tab"
  - "Windsurf Command"
  - "App Deploys"
  - "Prompt Engineering"
  - "Security"
  - "Troubleshooting"
  - "Pricing"
  - "Features"
  - "Configuration"
llm_processing_instructions: # [cite: 12, 296]
  llm_focus_areas: # [cite: 302]
    - "Cascade/Cascade Memories/Rules for Cascade" # Details on rule definition and best practices
    - "Cascade/Workflows" # How to create and use workflows
    - "Cascade/Cascade MCP Integration" # MCP setup and mcp_config.json
    - "Context Awareness/Local Indexing" # How context is gathered and managed
    - "Windsurf Editor/Windsurf Advanced Configuration" # Settings relevant to environment customization
    - "Prompt Engineering for Windsurf" # Guidelines for effective prompting
  summary_points_to_emphasize: # [cite: 306]
    - "The functionality of Cascade Memories, especially user-defined Rules (global, workspace, activation modes)."
    - "How to create and use Workflows for automating repetitive tasks."
    - "The process of integrating MCP servers via mcp_config.json and the plugin store."
    - "Context awareness mechanisms, including local indexing and the .codeiumignore file."
    - "Best practices for prompt engineering within Windsurf."
  example_user_questions_answered: # [cite: 312]
    - "How do I define rules for Cascade in Windsurf?"
    - "What are the different activation modes for Windsurf rules?"
    - "How can I integrate custom MCP tools with Cascade?"
    - "How does local indexing work in Windsurf for context awareness?"
    - "What are some best practices for writing prompts for Windsurf?"
---


# Windsurf Documentation

## Table of Contents

* [Cascade](#cascade)
    * [Overview of Cascade](#overview-of-cascade)
        * [Opening Cascade](#opening-cascade)
        * [Key Cascade Features](#key-cascade-features)
        * [Tools and Package Management](#tools-and-package-management)
        * [Reverting to Previous Steps](#reverting-to-previous-steps)
        * [Real-Time Awareness](#real-time-awareness)
        * [Sending Problems to Cascade](#sending-problems-to-cascade)
        * [Explain and Fix Errors](#explain-and-fix-errors)
        * [Ignoring Files in Cascade](#ignoring-files-in-cascade)
        * [Linter Integration](#linter-integration)
        * [Sounds for Cascade Notifications](#sounds-for-cascade-notifications)
        * [Sharing Your Cascade Conversation](#sharing-your-cascade-conversation)
        * [Simultaneous Cascade Instances](#simultaneous-cascade-instances)
    * [Cascade Plans and Credit Usage](#cascade-plans-and-credit-usage)
        * [Understanding Prompt Credits](#understanding-prompt-credits)
        * [Windsurf Plans](#windsurf-plans)
        * [Managing Credits](#managing-credits)
        * [Credit Usage Examples](#credit-usage-examples)
        * [Detailed Plan Usage Information](#detailed-plan-usage-information)
        * [Canceling Your Paid Plan](#canceling-your-paid-plan)
    * [App Deploys](#app-deploys)
        * [Overview of App Deploys](#overview-of-app-deploys)
        * [Supported Deployment Providers](#supported-deployment-providers)
        * [How App Deploys Work](#how-app-deploys-work)
        * [Using App Deploys](#using-app-deploys)
        * [Team Deploys](#team-deploys)
        * [Security Considerations for App Deploys](#security-considerations-for-app-deploys)
        * [Claiming Your Deployment](#claiming-your-deployment)
        * [Rate Limits for App Deploys](#rate-limits-for-app-deploys)
        * [Supported Frameworks for App Deploys](#supported-frameworks-for-app-deploys)
        * [Troubleshooting App Deploys](#troubleshooting-app-deploys)
    * [Image Upload in Cascade](#image-upload-in-cascade)
    * [Web and Docs Search](#web-and-docs-search)
        * [Overview of Web and Docs Search](#overview-of-web-and-docs-search)
        * [Quick Start for Web and Docs Search](#quick-start-for-web-and-docs-search)
        * [Reading Pages with Cascade](#reading-pages-with-cascade)
    * [Cascade Memories](#cascade-memories)
        * [How to Manage Memories](#how-to-manage-memories)
        * [Rules for Cascade](#rules-for-cascade)
    * [Workflows](#workflows)
        * [How Workflows Function](#how-workflows-function)
        * [How to Create a Workflow](#how-to-create-a-workflow)
    * [Cascade MCP Integration](#cascade-mcp-integration)
        * [Adding a New MCP Plugin](#adding-a-new-mcp-plugin)
        * [`mcp_config.json` File](#mcp_configjson-file)
        * [Notes on MCP Integration](#notes-on-mcp-integration)
* [Common Use Cases](#common-use-cases)
    * [Code Generation](#code-generation)
    * [Unit Test Generation](#unit-test-generation)
    * [Internal Code Commentary](#internal-code-commentary)
    * [API Documentation and Integration](#api-documentation-and-integration)
    * [Code Refactoring](#code-refactoring)
* [Context Awareness](#context-awareness)
    * [Overview of Context Awareness](#overview-of-context-awareness)
        * [Default Context Sources](#default-context-sources)
        * [Knowledge Base (Beta)](#knowledge-base-beta)
        * [Chat-Specific Context Features](#chat-specific-context-features)
        * [Frequently Asked Questions (FAQs) about Context Awareness](#frequently-asked-questions-faqs-about-context-awareness)
    * [Local Indexing](#local-indexing)
        * [How Local Indexing Works](#how-local-indexing-works)
        * [How to Toggle the Indexing Engine](#how-to-toggle-the-indexing-engine)
        * [`.codeiumignore` for Local Indexing](#codeiumignore-for-local-indexing)
        * [System Requirements for Local Indexing](#system-requirements-for-local-indexing)
* [Security](#security)
    * [Reporting Security Concerns](#reporting-security-concerns)
        * [Public GPG Key for Security Reporting](#public-gpg-key-for-security-reporting)
        * [Security Reporting Policy](#security-reporting-policy)
        * [Safe Harbor for Security Researchers](#safe-harbor-for-security-researchers)
* [Troubleshooting](#troubleshooting)
    * [Common Windsurf Issues](#common-windsurf-issues)
        * [General Windsurf Frequently Asked Questions (FAQ)](#general-windsurf-frequently-asked-questions-faq)
    * [Gathering Logs](#gathering-logs)
* [Windsurf Editor](#windsurf-editor)
    * [Models Available in Windsurf Editor](#models-available-in-windsurf-editor)
        * [Premium Models and Credit Costs](#premium-models-and-credit-costs)
        * [Cascade Base Model](#cascade-base-model)
    * [Windsurf Tab Feature](#windsurf-tab-feature)
        * [Keyboard Shortcuts for Tab](#keyboard-shortcuts-for-tab)
        * [Tab to Jump Functionality](#tab-to-jump-functionality)
        * [Tab to Import Functionality](#tab-to-import-functionality)
        * [Tab Settings](#tab-settings)
        * [Fill In The Middle (FIM) with Tab](#fill-in-the-middle-fim-with-tab)
    * [Windsurf Command Feature](#windsurf-command-feature)
        * [Models for Windsurf Command](#models-for-windsurf-command)
        * [Terminal Command with Windsurf Command](#terminal-command-with-windsurf-command)
        * [Best Practices for Using Windsurf Command](#best-practices-for-using-windsurf-command)
    * [Code Lenses](#code-lenses)
        * [Explain, Refactor, and Add Docstring Code Lenses](#explain-refactor-and-add-docstring-code-lenses)
    * [Smart Paste](#smart-paste)
    * [Terminal Integration](#terminal-integration)
        * [Using Command in the Terminal](#using-command-in-the-terminal)
        * [Sending Terminal Selection to Cascade](#sending-terminal-selection-to-cascade)
        * [Auto-Executed Cascade Commands in Terminal](#auto-executed-cascade-commands-in-terminal)
    * [Previews (Beta)](#previews-beta)
        * [Sending Elements to Cascade from Previews](#sending-elements-to-cascade-from-previews)
        * [In-IDE Preview Functionality](#in-ide-preview-functionality)
        * [How to Disable Previews](#how-to-disable-previews)
    * [AI Commit Messages](#ai-commit-messages)
        * [How AI Commit Messages Work](#how-ai-commit-messages-work)
        * [Best Practices for AI Commit Messages](#best-practices-for-ai-commit-messages)
        * [Limitations of AI Commit Messages](#limitations-of-ai-commit-messages)
        * [Privacy Considerations with AI Commit Messages](#privacy-considerations-with-ai-commit-messages)
    * [Windsurf Advanced Configuration](#windsurf-advanced-configuration)
        * [Enabling Cascade Access to `.gitignore` Files](#enabling-cascade-access-to-gitignore-files)
        * [SSH Support](#ssh-support)
        * [Dev Containers (Beta)](#dev-containers-beta)
        * [Windows Subsystem for Linux (WSL) (Beta)](#windows-subsystem-for-linux-wsl-beta)
        * [Extension Marketplace Configuration](#extension-marketplace-configuration)
* [Prompt Engineering for Windsurf](#prompt-engineering-for-windsurf)
    * [Components of a High-Quality Prompt](#components-of-a-high-quality-prompt)
    * [Prompt Examples](#prompt-examples)

---

## Cascade

### Overview of Cascade

Cascade allows users to expose [AI Flows](https://windsurf.com/flows), a new way of coding with Artificial Intelligence (AI).

#### Opening Cascade

To open Cascade, press `Cmd/Ctrl+L` or click the Cascade icon in the top right corner of the Windsurf window.

#### Key Cascade Features

* **Model Context Protocol (MCP) Integration:** MCP servers extend the agent’s capabilities. (Further details are available in the [Cascade MCP Integration](#cascade-mcp-integration) section).
* **Model Selection:** Select your desired model from the selection menu located below the Cascade conversation input box. A full list of available models can be found by consulting the [Windsurf Models documentation](https://docs.windsurf.com/windsurf/models).
* **Write/Chat Modes:** Cascade offers two modes: **Write** and **Chat**.
    * **Write mode** allows Cascade to create and make modifications to your codebase.
    * **Chat mode** is optimized for questions regarding your codebase or general coding principles.
    * While in Chat mode, Cascade may propose new code. If you accept the proposed code, it will be added to your codebase.

#### Tools and Package Management

Cascade has a variety of tools at its disposal, including:

* Search
* Analyze
* [Web Search](https://docs.windsurf.com/windsurf/web-search)
* [Model Context Protocol (MCP)](https://docs.windsurf.com/windsurf/mcp)
* The [terminal](https://docs.windsurf.com/windsurf/terminal)

Cascade can detect which packages and tools you are using, identify ones that need to be installed, and even install them for you. For example, you can ask Cascade how to run your project and press "Accept."

#### Reverting to Previous Steps

You have the ability to revert changes that Cascade has made. To do this, simply hover your mouse over the original prompt and click on the revert arrow on the right, or revert directly from the table of contents. This action will revert all code changes back to the state of your codebase at the desired step.

#### Real-Time Awareness

A unique capability of Windsurf and Cascade is its awareness of your real-time actions. This removes the need to prompt with context about your prior actions. Simply instruct Cascade to “Continue”.

#### Sending Problems to Cascade

When you encounter problems in your code that appear in the Problems panel at the bottom of the editor, click the `Send to Cascade` button to bring them into the Cascade panel as an @ mention.

#### Explain and Fix Errors

For any errors that you run into from within the editor, you can highlight the error and click `Explain and Fix` to have Cascade resolve it for you.

#### Ignoring Files in Cascade

If you would like Cascade to ignore specific files, you can add these files to a `.codeiumignore` file located at the root of your workspace. This will prevent Cascade from viewing, editing, or creating files within the designated paths. You can declare the file paths using a format similar to `.gitignore`.

#### Linter Integration

Cascade can automatically fix linting errors on generated code. This feature is enabled by default. It can be disabled by clicking `Auto-fix` on the tool call, and then clicking `disable`. This edit will not consume any credits.

When Cascade makes an edit with the primary goal of fixing lints that it created and auto-detected, it may discount the edit to be free of credit charge. This is in recognition of the fact that fixing lint errors increases the number of tool calls that Cascade makes.

#### Sounds for Cascade Notifications

You can enable a sound to play when Cascade finishes a trajectory, notifying you of its completion. Enable this feature via `Windsurf Settings` > `Cascade` > `Enable Sounds for Cascade`.

#### Sharing Your Cascade Conversation

You can share your Cascade trajectories with your team by clicking the `...` (Additional options) button in the top right of the Cascade panel, and then clicking `Share Conversation`.

#### Simultaneous Cascade Instances

Users can have multiple Cascade instances running simultaneously. You can navigate between them using the dropdown menu in the top left of the Cascade panel.

---

### Cascade Plans and Credit Usage

#### Understanding Prompt Credits

Prompt credits are consumed whenever a message is sent to Cascade with a premium model. Every model has its own credit multiplier, with the default message costing 1 credit. You can view all available models and their associated costs on the [Windsurf Models page](https://docs.windsurf.com/windsurf/models).

Upon using all of your credits, select premium models will no longer be accessible. However, you will still be able to use free models such as Cascade Base. In many cases, Cascade Base is sufficient for various agentic workflows, including code refactors, Question and Answer (Q&A) sessions, and more.

#### Windsurf Plans

Windsurf offers several plans:

* **Free Plan:** ([Details on using the Free plan](https://docs.windsurf.com/windsurf/cascade/usage#using-a-free-plan))
    * 25 prompt credits
    * Unlimited Windsurf Tab
    * Unlimited Previews
    * 1 App Deploy per day
* **Pro Trial (2 weeks):** ([Details on using the Pro Trial](https://docs.windsurf.com/windsurf/cascade/usage#using-a-free-pro-trial))
    * 100 prompt credits
    * Unlimited Windsurf Tab
    * Unlimited Previews
    * 10 App Deploys per day
* **Pro Plan:** ([Details on using the Pro plan](https://docs.windsurf.com/windsurf/cascade/usage#using-pro-plan)) Includes everything in the Free plan, plus:
    * 500 prompt credits
    * Add-on prompt credits at $10/250 credits
    * All premium models
* **Teams Plan:** ([Details on using the Teams plan](https://docs.windsurf.com/windsurf/cascade/usage#using-teams-plan)) Includes everything in the Pro plan, plus:
    * 500 prompt credits/user/month
    * Add-on prompt credits at $40/1000 credits
    * Centralized billing
    * Admin dashboard with analytics
    * Priority support
    * Access control features available to add
* **Enterprise Plan:** ([Details on using the Enterprise plan](https://docs.windsurf.com/windsurf/cascade/usage#using-enterprise-plan)) Includes everything in the Teams plan, plus:
    * 1000 prompt credits/user/month
    * Add-on prompt credits at $40/1000 credits
    * Role-Based Access Control (RBAC)
    * Single Sign-On (SSO) & System for Cross-domain Identity Management (SCIM)
    * Highest priority support
    * Longer context

If you run out of credits on any paid plan, you will have the option of [purchasing additional credits](https://docs.windsurf.com/windsurf/cascade/usage#purchasing-additional-credits) or setting up [Automatic Credit Refills](https://docs.windsurf.com/windsurf/cascade/usage#automatic-credit-refills).

After upgrading, your paid plan will start immediately, and you’ll have access to premium models again. To learn more about the quotas and features per pricing plan, [view pricing details](https://windsurf.com/pricing).

#### Managing Credits

##### Errors and Credit Consumption

If a user message is unsuccessful, prompt credits will not be consumed. For example, if Cascade attempts to write to a file but that file has unsaved changes, the operation will fail and it will not consume a credit.

##### Viewing Your Usage

There are a few ways to view your credit usage:

* Go to Cascade usage directly by clicking on the overflow menu (`...`) and then selecting “Cascade Usage”.
* View the settings panel by clicking on “Windsurf Settings” on the status bar, followed by selecting the “Plan Info” tab.
* You can also view it on your plan page at [windsurf.com/plan](https://windsurf.com/plan) after you’re authenticated.

##### Upgrading to a Paid Plan

To learn more about paid features or to upgrade to a paid plan, [visit the plan information page](https://windsurf.com/plan). Paid plans include Pro for individuals, Teams for organizations, and Enterprise for larger companies.

We accept all major credit cards, Apple Pay, Cash App Pay, Google Pay, Link, WeChat Pay, and Alipay. If you have a payment method not listed, please [contact support](https://windsurf.com/support). You may need to disable your Virtual Private Network (VPN) to view the relevant payment methods for your region.

##### What Happens When You Run Out of Prompt Credits?

If you no longer have prompt credits, you have two options:

* You can purchase additional prompt credits to continue using premium models.
* You can use Write or Chat mode with the Cascade Base model. Note that no prompt credits will be used when on the Cascade Base model.

##### Automatic Credit Refills

We’ve introduced Automatic Credit Refills so that you no longer need to manually purchase additional credits. Under your plan settings page on the Windsurf website, you can specify a maximum amount of credits and other refill settings. The system will automatically “top-up” your credits as you start running low (below 15 credits).

Automatic Credit Refills are purchased in configurable increments (multiples of $10 for Pro and $40 for Teams) and are subject to maximum monthly budget caps ($50 by default for Pro users and $160 for Teams users). This ensures you won’t lose access to Cascade during critical work.

##### Purchasing Additional Credits

If you run out of prompt credits, you can purchase additional credits on [the billing website](https://windsurf.com/plan). Additional prompt credits can be purchased at a rate of $10 for 250 credits for Pro users.

For Team and Enterprise plans, additional credits are purchased within and treated as a pool amongst all members of the team at a rate of $40 for 1000 pooled credits. Please contact your Teams admin to purchase more credits if you’re on a team plan.

#### Credit Usage Examples

To explain how credits work, here’s a simple example:

When you send a message to Cascade with a premium model, 1 Prompt credit is consumed. It doesn’t matter how many actions Cascade takes to fulfill your request—whether it searches your codebase, analyzes files, or makes edits—you only pay for the initial prompt.

This simplified system makes it much easier to predict and manage your usage. No more complicated calculations of flow actions or different credit types.

#### Detailed Plan Usage Information

##### Using a Free Pro Trial

The Pro Trial lasts for 2 weeks and includes unlimited Windsurf Tab, 100 prompt credits, Previews, and Deploys.

When you’re on a Pro Trial, you’ll have access to premium features. To get started, ask Cascade a question. In Write and Chat mode, Cascade is optimized to fully understand your codebase and leverages tool calls to assist you. By default, all of your requests will use premium models until you run out of credits.

After your trial period ends, you’ll need to upgrade to a paid plan to continue using premium models.

If you don’t upgrade during the Free Trial period, you’ll be downgraded to our Free plan which includes 5 prompt credits per month.

##### Using the Pro Plan

The Pro plan costs $15/month and includes:

* 500 prompt credits/month
* All premium models
* Previews
* App Deploys

Additional prompt credits can be purchased at a rate of $10 for 250 credits.

While on Pro, you’ll have access to a monthly quota of prompt credits. You can view how many credits you have remaining in the Windsurf Settings panel that’s accessible in the status bar.

If you’re running low on credits, Cascade will notify you so that you can purchase additional credits or enable Automatic Credit Refills. To purchase additional credits, visit the billing website and select “Purchase credits”. The credits purchased will roll over to the following usage month if there are any remaining.

If you want to reduce your consumption of prompt credits, you can use the Cascade Base model in Write or Chat mode. Using the Cascade Base model does not consume any prompt credits.

In addition to prompt credits, Pro comes with unlimited Fast Autocomplete and unlimited premium model requests with Command.

##### Using the Teams Plan

The Teams plan costs $30/user/month (up to 200 users) and includes:

* 500 prompt credits/user/month
* Everything in Pro, plus:
    * Centralized billing
    * Admin dashboard with analytics
    * Priority support

Additional prompt credits can be purchased at a rate of $40 for 1000 pooled credits.

The Teams plan has a seat cap of 200 users. Coming soon, there will be an option to add Access Control features for +$10/user/month.

While on the Teams plan, each user will have access to a monthly quota of prompt credits. Unlike the previous system, base prompt credits are not pooled—each user has their own credit limit. However, purchased add-on prompt credits are pooled across the organization. You can view how many credits your team has remaining in the Windsurf Settings panel.

If your team is running low on credits, your administrator can purchase additional credits or enable Automatic Credit Refills. These add-on prompt credits purchased will roll over to the following usage month if there are any remaining.

##### Using the Enterprise Plan

The Enterprise plan costs $60/user/month (up to 200 users) and includes everything in Teams plus:

* 1000 prompt credits/user/month
* Role-Based Access Control (RBAC)
* Single Sign-On (SSO) & System for Cross-domain Identity Management (SCIM) (included)
* Longer model context lengths
* Highest priority support

Additional prompt credits can be purchased at a rate of $40 for 1000 pooled credits.

Coming soon, Enterprise will be self-serviceable with month-to-month pricing. The Enterprise plan includes self-serve SSO integration and enhanced security features.

For enterprise support, account management, and more involved deployments such as Hybrid or FedRAMP under an annual commitment, [contact our enterprise team via trust.windsurf.com](https://trust.windsurf.com/) for any standard security collateral.

##### Using a Free Plan

The Free plan comes with:

* 25 prompt credits/month
* Unlimited Windsurf Tab
* Unlimited Previews
* 1 App Deploy per day

Windsurf can still be used for free after your credits are exhausted. Our in-house Cascade Base model is constantly improving and is available for free, unlimited use.

When editing code, you’ll have access to unlimited Tab completions and AI command instructions. To learn more about features in Free and in paid tiers, [review the pricing details](https://codeium.com/pricing).

#### Canceling Your Paid Plan

To cancel your paid plan, visit the billing website. Upon canceling your paid plan, you’ll still have access to all of your credits from your monthly quota and add-on prompt credits until the end of the usage month. After the usage month, all add-on prompt credits will expire and you’ll be downgraded to the Free plan where you’ll be provided a limited number of prompt credits. If you change your mind and decide not to cancel before the end of the usage month, you can renew your plan by visiting the billing page.

---

### App Deploys

App Deploys lets you deploy web applications and sites directly within Windsurf through Cascade tool calls. This feature helps you share your work through public URLs, update your deployments, and claim projects for further customization. This feature is in beta, and support for additional frameworks, more robust builds, and other enhancements are coming soon.

#### Overview of App Deploys

With App Deploys, you can:

* Deploy a website or JavaScript (JS) web app to a public domain.
* Re-deploy to the same URL after making changes.
* Claim the project to your personal account.

#### Supported Deployment Providers

We currently support the following deployment provider:

* **Netlify:** For static sites and web applications.

#### How App Deploys Work

When you use App Deploys, your code is uploaded to our server and deployed to the provider under our umbrella account. The deployed site will be available at a public URL.

##### Deployment Process

1.  Cascade analyzes your project to determine the appropriate framework.
2.  Your project files are securely uploaded to our server.
3.  The deployment is created on the provider’s platform.
4.  You receive a public URL and a claim link.

##### Project Configuration

To facilitate redeployment, we create a `windsurf_deployment.yaml` (YAML Ain't Markup Language) file at the root of your project. This file contains information for future deployments, such as a project ID and framework.

#### Using App Deploys

To deploy your application, simply ask Cascade something like: `"Deploy this site"` or `"Deploy my React app"`. Cascade will guide you through the process and help troubleshoot common issues.

#### Team Deploys

Users on Teams and Enterprise plans can connect their Netlify accounts with their Windsurf accounts and deploy to their Netlify Team.

This can be toggled in Team Settings, which you can access via the Profile page or by [navigating to Team Deploy Settings](https://windsurf.com/team/team_settings/windsurf_settings/deploys).

#### Security Considerations for App Deploys

We take several precautions to ensure security:

* File size limits and validation
* Rate limiting based on your account tier
* Secure handling of project files

For added privacy, [visit clear-cookies.windsurf.build](https://clear-cookies.windsurf.build/) to check for and clear any cookies set by sites under `windsurf.build`. If any cookies show up, they shouldn’t be there, and clearing them helps prevent cross-site cookie issues and keeps your experience clean.

Windsurf sites are built by humans and AI, and while we encourage the AI to make best practice decisions, it’s smart to stay cautious. Windsurf isn’t responsible for issues caused by sites deployed by our users.

#### Claiming Your Deployment

After deploying, you’ll receive a claim URL. By following this link, you can claim the project on your personal provider account, giving you:

* Full control over the deployment
* Access to provider-specific features
* Ability to modify the domain name
* Direct access to logs and build information

#### Rate Limits for App Deploys

To prevent abuse, we apply these tier-based rate limits:

| Plan       | Deployments per day | Max unclaimed sites |
| :--------- | :------------------ | :------------------ |
| Free       | 1                   | 1                   |
| Pro        | 10                  | 5                   |

#### Supported Frameworks for App Deploys

App Deploys works with most popular JavaScript (JS) frameworks, including:

* Next.js
* React
* Vue
* Svelte
* Static HyperText Markup Language (HTML)/Cascading Style Sheets (CSS)/JS sites

#### Troubleshooting App Deploys

##### Failed Deployment Build

If your deployment fails:

1.  Check the build logs provided by Cascade.
2.  Ensure your project can build locally (run `npm run build` to test).
3.  Verify that your project follows the framework’s recommended structure.
4.  View the documentation for how to deploy [your framework to Netlify via `netlify.toml`](https://docs.netlify.com/configure-builds/file-based-configuration/).
5.  Consider claiming the project to access detailed logs on the provider’s dashboard.

##### Netlify Site Not Found

This likely means that your build failed. Please claim your site (you can find it on [your deploy history](https://windsurf.com/deploy)) and check the build logs for more details. Often, you can paste your build logs into Cascade and ask for help.

##### Changing Your Subdomain / URL

###### Updating `netlify.app` domain

You can change your subdomain by claiming your deployment and updating the Netlify site settings. This will update your `.netlify.app` domain.

###### Updating custom `.windsurf.build` subdomain

To update your custom `.windsurf.build` subdomain, you’ll need to deploy a new site with a new subdomain:

1.  Delete the `windsurf_config.yaml` file from your project.
2.  Ask Cascade to deploy a new site with a new subdomain and tell it which one you want.
3.  It can help to start a new conversation or clear your auto-generated memories so that Cascade doesn’t try to re-deploy to the old subdomain.
4.  When you create a new deployment, you’ll be able to press the “Edit” button on the subdomain User Interface (UI) to update it prior to pressing “Deploy”.

##### Error: `Unable to get project name for project ID`

This error occurs when your project ID is not found in our system of records or if Cascade is using the subdomain as the project ID incorrectly. To fix this:

1.  Check that the project still exists in your Netlify account (assuming it is claimed).
2.  Check that the project ID is in the `windsurf_deployment.yaml` file. If it is not in the file, you can download your config file from your [deploy history](https://windsurf.com/deploy) dropdown.
3.  Try redeploying and telling Cascade to use the `project_id` from the `windsurf_deployment.yaml` file more explicitly.

---

### Image Upload in Cascade

Add images to your prompt to be referenced in Cascade’s suggestions. Items such as screenshots of your Figma designs, wireframes, and similar visual aids are all suitable for upload.

This feature is currently only available for use with GPT-4o and Claude 3.5 Sonnet models.

Simply drag in or paste an image, or click on the “Add image” button below the input text box to include it in your message.

**Note:** Dragging an image into Cascade from Windsurf’s File Explorer may not work.

---

### Web and Docs Search

Cascade can now intuitively parse through and chunk up web pages and documentation, providing real-time context to the models. The key to understanding this feature is that Cascade browses the Internet as a human would.

Our web tools are designed to get only the necessary information to efficiently use your credits.

#### Overview of Web and Docs Search

[Watch Video: YouTube video player (Web Search Overview)](https://www.youtube.com/embed/moIySJ4d0UY)

To help you better understand how Web Search works, we’ve recorded a short video covering the key concepts and best practices.

#### Quick Start for Web and Docs Search

The fastest way to get started is to activate web search in your Windsurf Settings in the bottom right corner of the editor. You can activate it in a couple of different ways:

1.  Ask a question that probably needs the Internet (e.g., “What’s new in the latest version of React?”).
2.  Use `@web` to force a docs search.
3.  Use `@docs` to query over a list of docs that we are confident we can read with high quality.
4.  Paste a URL into your message.

Cascade can deduce that certain prompts from the user may require a real-time web search to provide the optimal response. In these cases, Cascade will perform a web search and provide the results to the user. This can happen automatically or manually using the `@web` mention.

#### Reading Pages with Cascade

Cascade can read individual pages for things like documentation, blog posts, and GitHub files. The page reads happen entirely on your device within your network, so if you’re using a VPN, you shouldn’t have any problems.

Pages are picked up either from web search results, inferred based on the conversation, or from URLs pasted directly into your message.

We break pages into multiple chunks, similar to how a human reads a page: for a long page, we skim to the desired section and then read the relevant text. Cascade operates in the same way.

It’s worth noting that not all pages can be parsed. We are actively working on improving the quality of our website reading. If you have specific sites you’d like us to handle better, feel free to file a feature request.

---

### Cascade Memories

`Memories` is the system for sharing and persisting context across conversations in Windsurf.

Windsurf provides two mechanisms for this:
1.  **Memories:** Which Cascade can automatically generate.
2.  **Rules:** Which users manually define at local (workspace) and global levels.

#### How to Manage Memories

Memories and Rules can be accessed and configured at any time by clicking on the `Customizations` icon in the top right slider menu in Cascade, or via “Windsurf - Settings” in the bottom-right hand corner. To edit an existing memory, simply click into it and then click the `Edit` button.

During a conversation, Cascade can automatically generate and store memories if it encounters context that it believes is useful to remember.

Additionally, you can ask Cascade to create a memory at any time. Just prompt Cascade to “create a memory of …”.

Cascade’s autogenerated memories are associated with the workspace that they were created in, and Cascade will retrieve them when it believes that they are relevant. Memories generated in one workspace will not be available in another.

#### Rules for Cascade

Users can explicitly define their own rules for Cascade to follow. Rules can be defined at either the global level or the workspace level.

* `global_rules.md`: Rules applied across all workspaces.
* `.windsurf/rules`: Workspace-level repository containing rules that are tied to globs or natural language descriptions.

To get started with Rules, click on the `Customizations` icon in the top right slider menu in Cascade, then navigate to the `Rules` panel. Here, you can click on the `+ Global` or `+ Workspace` button to create new rules at either the global or workspace level, respectively.

Rules files are limited to 6000 characters each. Any content above 6000 characters will be truncated, and Cascade will not be aware of it.

If the total of your global rules and local rules exceeds 12,000 characters, priority will be given to the global rules, followed by the workspace rules. Any rules beyond 12,000 characters will be truncated.

##### Activation Modes

At the rule level, you can define how a rule should be activated for Cascade. There are 4 modes:

1.  **Manual:** This rule can be manually activated via `@mention` in Cascade’s input box.
2.  **Always On:** This rule will always be applied.
3.  **Model Decision:** Based on a natural language description of the rule the user defines, the model decides whether to apply the rule.
4.  **Glob:** Based on the glob pattern that the user defines (e.g., `*.js`, `src/**/*.ts`), this rule will be applied to all files that match the pattern.

##### Best Practices for Rules

To help Cascade follow your rules effectively, follow these best practices:

* Keep rules simple, concise, and specific. Rules that are too long or vague may confuse Cascade.
* There’s no need to add generic rules (e.g., “write good code”), as these are already baked into Cascade’s training data.
* Format your rules using bullet points, numbered lists, and markdown. These are easier for Cascade to follow compared to a long paragraph. For example:
    * Use type hints for all function definitions.
    * Docstrings should follow Google Python Style Guide.
* Extensible Markup Language (XML) tags can be an effective way to communicate and group similar rules together. For example:

    ```xml
    <rule_group name="Python Specific Rules">
        <rule description="Use type hints for all function definitions.">
        def my_function(param1: str, param2: int) -> bool:
            # function body
        </rule>
        <rule description="Docstrings should follow Google Python Style Guide.">
        """This is a docstring.

        Args:
            param1 (str): Description of param1.
            param2 (int): Description of param2.

        Returns:
            bool: Description of return value.
        """
        </rule>
    </rule_group>
    ```

---

### Workflows

Workflows enable users to define a series of steps to guide Cascade through a repetitive set of tasks, such as deploying a service or responding to Pull Request (PR) comments.

These Workflows are saved as markdown files, allowing users and their teams an easy, repeatable way to run key processes.

Once saved, Workflows can be invoked in Cascade via a slash command with the format of `/[name-of-workflow]`.

#### How Workflows Function

Rules generally provide Large Language Models (LLMs) with guidance by providing persistent, reusable context at the prompt level.

Workflows extend this concept by providing a structured sequence of steps or prompts at the trajectory level, guiding the model through a series of interconnected tasks or actions.

To execute a workflow, users simply invoke it in Cascade using the `/[workflow-name]` command.

Upon invocation, Cascade sequentially processes each step defined in the workflow, performing actions or generating responses as specified.

#### How to Create a Workflow

To get started with Workflows, click on the `Customizations` icon in the top right slider menu in Cascade, then navigate to the `Workflows` panel. Here, you can click on the `+ Workflow` button to create a new Workflow.

Workflows are saved as markdown files within the repository root of `.windsurf/workflows/` and contain a title, description, and a series of steps with specific instructions for Cascade to follow.

##### Generate a Workflow with Cascade

You can also ask Cascade to generate Workflows for you. This works particularly well for workflows involving a series of steps in a particular Command Line Interface (CLI) tool.

---

### Cascade MCP Integration

**Model Context Protocol (MCP)** is a protocol that enables Large Language Models (LLMs) to access custom tools and services. An MCP client (Cascade, in this case) can make requests to MCP servers to access tools that they provide. Cascade now natively integrates with MCP, allowing you to bring your own selection of MCP servers for Cascade to use. See the [official MCP documentation](https://modelcontextprotocol.io/) for more information.

#### Adding a New MCP Plugin

New MCP plugins can be added from the Plugin Store, which you can access by clicking on the `Plugins` icon in the top right menu in the Cascade panel, or from the `Windsurf Settings` > `Cascade` > `Plugins` section.

If you cannot find your desired MCP plugin, you can add it manually by editing the raw `mcp_config.json` (JavaScript Object Notation) file.

Official MCP plugins will show up with a blue checkmark, indicating that they are made by the parent service company.

When you click on a plugin, simply click `Install` to expose the server and its tools to Cascade.

Windsurf supports two [transport types](https://modelcontextprotocol.io/docs/concepts/transports) for MCP servers: `stdio` and `/sse`.

For `/sse` servers, the URL should reflect that of the endpoint and resemble `https://<your-server-url>/sse`.

Each plugin has a certain number of tools it has access to. Cascade has a limit of 100 total tools that it has access to at any given time.

At the plugin level, you can navigate to the Tools tab and toggle the tools that you wish to enable. Or, from the `Windsurf Settings`, you can click on the `Manage plugins` button.

#### `mcp_config.json` File

The `~/.codeium/windsurf/mcp_config.json` file is a JSON file that contains a list of servers that Cascade can connect to.

The JSON should follow the same schema as the config file for Claude Desktop.

Here’s an example configuration, which sets up a single server for Google Maps:

```json
{
  "mcp_servers": [
    {
      "name": "Google Maps",
      "description": "MCP server for Google Maps.",
      "transport": {
        "type": "stdio",
        "command": ["python", "main.py"],
        "args": ["--service", "google-maps"],
        "working_directory": "/path/to/google-maps-server",
        "env": {
          "Maps_API_KEY": "YOUR_API_KEY"
        }
      }
    }
  ]
}
````

Be sure to provide the required arguments and environment variables for the servers that you want to use.

See the [official MCP server reference repository](https://github.com/modelcontextprotocol/servers) or [OpenTools](https://opentools.com/) for some example servers.

#### Notes on MCP Integration

  * Since MCP tool calls can invoke code written by arbitrary server implementers, we do not assume liability for MCP tool call failures.
  * We currently only support [tools](https://modelcontextprotocol.io/docs/concepts/tools), not [prompts](https://modelcontextprotocol.io/docs/concepts/prompts) nor [resources](https://modelcontextprotocol.io/docs/concepts/resources). In other words, Cascade will be able to request and use a server’s tools, but not the other endpoints that a server exposes.

-----

## Common Use Cases

Windsurf serves a variety of use cases at a high level. However, we see certain use cases to be more common than others, especially among our enterprise customers within their production codebases.

### Code Generation

**Guidance:** Windsurf should work well for this use case. Windsurf features include single-line suggestions, multi-line suggestions, and Fill-in-the-Middle (FIM) completions. (FIM is detailed further in the [Windsurf Tab](https://www.google.com/search?q=%23fill-in-the-middle-fim-with-tab) section).

**Best Practices:** Ensuring usage of Next Completion (`⌥ + ]`), Context Pinning, @ Mentions, and Custom Context will provide the best results.

### Unit Test Generation

**Guidance:** Basic usage of Windsurf for generating unit tests should reliably generate 60-70% of unit tests. Edge case coverage will only be as good as the user prompting the model.

**Best Practices:**

  * Use @ Mentions.
  * Employ Prompt Engineering best practices. Examples include:
      * "Write unit test for `@function-name` that tests all edge cases for X and for Y (e.g., email domain)."
      * "Use `@testing-utility-class` to write a unit test for `@function-name`."
  * This approach is good for low-hanging fruit use cases. For very specific Application Programming Interface (API) specs or in-house libraries, Windsurf will not know the intricacies well enough to ensure the quality of generated sample data.
  * Be very specific about the interface you expect.
  * Think about the complexity of the task and if a single-shot Large Language Model (LLM) call will be sufficient to address it.

### Internal Code Commentary

**Guidance:**

  * Windsurf should work well for this use case. Use Windsurf Command or Windsurf Chat to generate in-line comments and code descriptions.
  * Generally, the Refactor button or Windsurf Command are the best ways to prompt for improvements.
  * Windsurf Chat is the best place to ask for explanations or clarifications.
  * For generating header files (e.g., from C++ source files), the best way is to create the header file, open chat, @ mention the function in the `.cpp` file, and ask Windsurf to write the header function. Then, do this iteratively for each function in the `.cpp` file to ensure no hallucinations.

**Best Practices:**

  * Use @ Mentions.
  * Use Code Lenses as much as possible to ensure the scope of the LLM call is correct.
  * Use the dropdown prompts (i.e., Windsurf’s Refactor button) – these have custom prompts that are better engineered to deliver the answer you’d more likely expect.
  * Generally avoid trying to write a whole header file with one LLM call. Breaking down the granularity of the work makes the quality of the generated code significantly higher.

### API Documentation and Integration

**Guidance:**

  * This is similar to test coverage where parts of the API specification that are common across many libraries, Windsurf would be able to accurately decorate. However, for things that are built specially for your in-house use case, Windsurf might struggle to achieve the quality you expect.
  * Windsurf’s context length for a single LLM call is 16,000 tokens. Thus, depending on the scope of your search, Windsurf’s repo-wide search capability may not be sufficient. Repo-wide, multi-step, multi-edit tasks will be supported in upcoming future Windsurf products. This is fundamentally a multi-step problem that single-shot LLM calls (i.e., current functionality of all AI code assistants) are not well equipped to address. Additionally, the accuracy of the result must be much higher than other use cases as integrations are especially fragile.

**Best Practices:**

  * Similar to test coverage, as much as possible, walk Windsurf’s model through the best way to think about what the API is doing, and it will be able to decorate better.
  * Windsurf is not well-equipped to solve repo-wide integration problems today. If you’d like to test the extent of Windsurf’s existing functionality, build out a step-by-step plan and prompt Windsurf individually with each step and a high level of detail to guide the AI.

### Code Refactoring

**Guidance:**

  * Ensure proper scoping using Windsurf Code Lenses or @ Mentions to make sure all of the necessary context is passed to the LLM.
  * Context lengths for a single LLM call are finite. Thus, depending on the scope of your refactor, this finite context length may be an issue (and for that matter, any single-shot LLM paradigm). Repo-wide, multi-step, multi-edit tasks are now supported in Windsurf’s [Cascade feature](https://www.google.com/search?q=%23cascade).
  * Windsurf’s context length for a single LLM call is 16,000 tokens. Thus, depending on the scope of your refactor, Windsurf’s context length may be an issue.

**Best Practices:**

  * Try to break down the prompt as much as possible. The simpler and shorter the command for refactoring, the better.

-----

## Context Awareness

### Overview of Context Awareness

Windsurf’s context engine builds a deep understanding of your codebase, past actions, and next intent.

Historically, code-generation approaches focused on fine-tuning Large Language Models (LLMs) on a codebase, which is difficult to scale to the needs of every individual user. A more recent and popular approach leverages Retrieval-Augmented Generation (RAG), which focuses on techniques to construct highly relevant, context-rich prompts to elicit accurate answers from an LLM.

We’ve implemented an optimized RAG approach to codebase context, which produces higher quality suggestions and fewer hallucinations.

#### Default Context Sources

Out of the box, Windsurf takes multiple relevant sources of context into consideration:

  * The current file and other open files in your Integrated Development Environment (IDE), which are often very relevant to the code you are currently writing.
  * The entire local codebase is then indexed (including files that are not open), and relevant code snippets are sourced by Windsurf’s retrieval engine as you write code, ask questions, or invoke commands.
  * For Pro users, we offer expanded context lengths, increased indexing limits, and higher limits on custom context and pinned context items.
  * For Teams and Enterprise users, Windsurf can also index remote repositories. This is useful for companies whose development organization works across multiple repositories.

#### Knowledge Base (Beta)

This feature allows teams to pull in Google Docs as shared context or knowledge sources for their entire team.

Currently, only Google Docs are supported. Images are not imported, but charts, tables, and formatted text are fully supported.

Admins must manually connect with Google Drive via OAuth, after which they can add up to 50 Google Docs as team knowledge sources.

Cascade will have access to the docs specified in the Windsurf dashboard. These docs do not obey individual user access controls, meaning if an admin makes a doc available to the team, all users will have access to it regardless of access controls on the Google Drive side.

##### Best Practices for Context Pinning

Context Pinning is great when your task in your current file depends on information from other files. Try to pin only what you need. Pinning too much may slow down or negatively impact model performance.

Here are some ideas for effective context pinning:

  * **Module Definitions:** Pinning class/struct definition files that are inside your repo but in a module separate from your currently active file.
  * **Internal Frameworks/Libraries:** Pinning directories with code examples for using frameworks/libraries.
  * **Specific Tasks:** Pinning a file or folder defining a particular interface (e.g., `.proto` files, abstract class files, config templates).
  * **Current Focus Area:** Pinning the “lowest common denominator” directory containing the majority of files needed for your current coding session.
  * **Testing:** Pinning a particular file with the class you are writing unit tests for.

#### Chat-Specific Context Features

When conversing with Windsurf Chat, you have various ways of leveraging codebase context, like [@-mentions](https://www.google.com/search?q=https://docs.windsurf.com/chat/overview%23mentions) or custom guidelines. See the [Windsurf Chat documentation](https://docs.windsurf.com/chat/overview) for more information.

#### Frequently Asked Questions (FAQs) about Context Awareness

##### Does Windsurf index my codebase?

Yes, Windsurf does index your codebase. It also uses LLMs to perform Retrieval-Augmented Generation (RAG) on your codebase using our own [M-Query techniques](https://youtu.be/DuZXbinJ4Uc?feature=shared&t=606).

Indexing performance and features vary based on your workflow and your Windsurf plan. For more information, please visit our [context awareness page](https://windsurf.com/context).

-----

### Local Indexing

The **Indexing Engine** is Windsurf’s codebase awareness service that powers:

  * Codebase-Aware [Chat](https://docs.windsurf.com/chat/overview)
  * Codebase-Aware [Autocomplete](https://docs.windsurf.com/autocomplete/overview)

Compared to regular context-aware Autocomplete and Chat, the Indexing Engine is able to retrieve context from across the entire codebase, not just files that you have recently interacted with. This significantly improves the quality of autocomplete and chat responses.

#### How Local Indexing Works

The Indexing Engine works in part by generating embeddings for your codebase that capture the underlying meaning. These embeddings can be queried using both Natural Language and related code snippets.

Windsurf Indexing does send snippets of code to a remote server to generate embeddings. However, no code or embeddings are stored remotely — all your data is stored on your own device.

#### How to Toggle the Indexing Engine

To toggle the Indexing Engine in VS Code, go to your “Settings (UI)” page, and search for “Windsurf Search”. You should see an option to enable search, and set the Max Workspace Size.

Then restart your IDE, and the change should be reflected.

You can see if your workspace is indexed by checking the “Context” pane in the “Chat” panel. If there is a green dot next to your workspace, then it is indexed and searchable.

#### `.codeiumignore` for Local Indexing

By default, Windsurf Indexing will ignore:

  * Paths specified in `.gitignore`
  * Files in `node_modules`
  * Hidden pathnames (starting with a period, `.`)

When a file is ignored, it will not be indexed and also does not count against the Indexing Max Workspace Size file counts.

If you want to further configure files that Windsurf Indexing ignores, you can add a `.codeiumignore` file to your repo root, with the same syntax as `.gitignore`.

#### System Requirements for Local Indexing

When first enabled, Windsurf will consume a fraction of Central Processing Unit (CPU) power while it indexes the workspace. Depending on your workspace size, this should take 5-10 minutes and only needs to happen once per workspace. CPU usage will return to normal automatically. Windsurf Indexing also requires Random Access Memory (RAM) (\~300MB for a 5000-file workspace).

The “Max Workspace Size (File Count)” setting determines the largest workspace for which Windsurf Indexing will try to index a particular workspace/module. If your workspace does not appear to be indexed, please try adjusting this number higher. For users with \~10GB of RAM, we recommend setting this no higher than 10,000 files.

-----

## Security

### Reporting Security Concerns

Windsurf takes the security of our products and services seriously. If you believe you have found a security vulnerability in any Windsurf-owned services, please report it to us as described below.

**Please do not report security vulnerabilities through public GitHub issues.**

Instead, please report them via email to [security@windsurf.com](mailto:security@windsurf.com).

Please include the following information in your report, including as much technical detail as possible:

  * Type of issue (e.g., buffer overflow, SQL injection, cross-site scripting, etc.)
  * The location of the affected source code (if applicable)
  * Any special configuration required to reproduce the issue
  * Step-by-step instructions to reproduce the issue
  * Proof-of-concept or exploit code (if possible)
  * Impact of the issue, including how an attacker might exploit it
  * Any other relevant information

This information will help us triage your report more quickly.

Please compile all information into a single email, encrypted with our public GNU Privacy Guard (GPG) key, include the name of the affected product, and the version of the product affected (if known).

#### Public GPG Key for Security Reporting

(The original document did not provide the GPG key itself, only a heading for it. This heading is preserved.)

##### Security Reporting Policy

Windsurf follows the principle of [Coordinated Vulnerability Disclosure](https://en.wikipedia.org/wiki/Coordinated_vulnerability_disclosure).

#### Safe Harbor for Security Researchers

Windsurf supports safe harbor for security researchers who:

  * Make a good faith effort to avoid privacy violations, destruction of data, and interruption or degradation of our services.
  * Only interact with accounts you own or with explicit permission of the account holder.
  * Do not exploit a security issue you discover for any reason other than testing.
  * Report any vulnerability you’ve discovered promptly.
  * Follow the guidelines outlined in this document.

We will not take legal action against you or administrative action against your account if you act according to this policy.

*Last updated: December 10, 2024*

-----

## Troubleshooting

### Common Windsurf Issues

#### General Windsurf Frequently Asked Questions (FAQ)

##### I’m experiencing rate limiting issues.

We’re subject to rate limits and unfortunately sometimes hit capacity for the premium models we work with. We are actively working on getting these limits increased and fairly distributing the capacity that we have. This should not be an issue forever. If you get this error, please wait a few moments and try again.

##### Pylance or Pyright isn’t working / Python syntax highlighting is broken or subpar.

We’ve developed a [Pyright extension specifically for Windsurf](https://www.google.com/search?q=https://docs.windsurf.com/windsurf/advanced%23windsurf-extensions). Please search for “Windsurf Pyright” or paste `@id:codeium.windsurfPyright` into the extension search.

##### How do I download Diagnostic logs to send to the Windsurf support team?

You can download diagnostic logs by going to your Cascade Panel, tapping the three dots (`...`) in the top right corner, and then clicking “Download Diagnostics”.

##### On MacOS, I see a pop-up: ‘Windsurf’ is damaged and cannot be opened.

This pop-up is due to a false positive in MacOS security features. You can usually resolve this by going to “System Settings -\> Privacy & Security” and clicking “Allow” or “Open anyway” for Windsurf. If this fails or is not possible, try the following steps:

1.  Ensure that Windsurf is placed under your `/Applications` folder and that you are running it from there.
2.  Check your processor type: if your Mac has an Intel chip, make sure you have the Intel version. If it’s Apple Silicon (like M1, M2 or M3), make sure you have the Apple Silicon version. You can select the processor type from the [Mac download page](https://windsurf.com/windsurf/download_mac).
3.  Try redownloading the Apple Disk Image (DMG) and reinstalling from [the official download page](https://windsurf.com/windsurf/download_mac), as the failing security feature is usually triggered on download.
4.  Make sure Windsurf (and the “Windsurf is Damaged” pop-up) is closed, and run `xattr -c "/Applications/Windsurf.app/"` in your terminal.

##### I received an error message about updates on Windows, or updates are not appearing on Windows.

For example:

> Updates are disabled because you are running the user-scope installation of Windsurf as Administrator.

We cannot auto-update Windsurf when it is run as Administrator. Please re-run Windsurf with User scope to update.

##### What domains should I whitelist for network filters/firewalls, VPNs, or proxies?

If you’re using any network filtering, firewalls, VPN services, or working in environments with restricted network access, you may experience connectivity issues with Windsurf. To ensure smooth operation, please whitelist the following domains in your network configuration:

  * `*.codeium.com`
  * `*.windsurf.com`
  * `*.codeiumdata.com`

##### On Linux, Windsurf quietly doesn’t launch, or crashes on launch.

This is usually due to an Electron permissions issue, which VSCode also has, and is expected when using the tarball on Linux. The easiest way to fix it is to run the following in your terminal:

```bash
sudo sysctl kernel.unprivileged_userns_clone=1
```

You should then be able to launch Windsurf. You can also just run `windsurf` with the flag `--no-sandbox`, though we don’t encourage this. If this fails, then try the steps below.

##### I received an error message saying ‘Windsurf failed to start’.

Please delete the following folder:

  * **Windows:** `C:\Users\<YOUR_USERNAME>\.codeium\windsurf\cascade`
  * **Linux/Mac:** `~/.codeium/windsurf/cascade`

Then try restarting the Integrated Development Environment (IDE).

##### My Cascade panel goes blank.

Please reach out to us if this happens. A screen recording would be much appreciated. This can often be solved by clearing your chat history (`~/.codeium/windsurf/cascade`).

-----

### Gathering Logs

If you’re having issues, the first step in the troubleshooting process is to retrieve the logs from your Integrated Development Environment (IDE). Here’s how you can get Windsurf logs for each of the major IDEs:

1.  Open the Command Palette (`Ctrl/Cmd + Shift + P` or go to View \> Command Palette).
2.  Type in “Download Windsurf Logs” and select the option that reads “Download Windsurf Logs File”.
3.  Export or copy the logs and attach the file to your ticket.

Alternatively, you can also click on the three dots (`...`) in the top right corner of the Cascade panel and select “Download Diagnostics”.

-----

## Windsurf Editor

### Models Available in Windsurf Editor

In the Cascade panel (`Ctrl/⌘ + L`), you can easily switch between different models of your choosing.

Under the text input box, you will see a model selection dropdown menu. You will see the following models available:

  * GPT-4o
  * GPT-4.1
  * o3 (medium reasoning)
  * o3 (high reasoning)
  * o4-mini-medium
  * o4-mini-high
  * Claude 3.5 Sonnet
  * Claude 3.7 Sonnet
  * Claude 3.7 Sonnet (Thinking)
  * DeepSeek-V3-0324
  * DeepSeek-R1
  * Gemini 2.0 Flash
  * Gemini 2.5 Flash
  * Gemini 2.5 Pro
  * xAI Grok-3
  * xAI Grok-3 mini (Thinking)
  * Cascade Base ⚡

#### Premium Models and Credit Costs

Due to the wide variation between the serving costs of each model, depending on the model you select, each of your input prompts will consume a different number of [prompt credits](https://www.google.com/search?q=https://docs.windsurf.com/windsurf/usage%23user-prompt-and-flow-action-credits).

Below you will find a breakdown of how many prompt credits you will be charged for each model:

| Model                      | Prompt credits | Free | Trial/Pro | Teams | Image Upload |
| :------------------------- | :------------- | :--- | :-------- | :---- | :----------- |
| GPT-4o                     | 1              | ✓    | ✓         | ✓     | ✓            |
| GPT-4.1                    | 0.25           | ✓    | ✓         | ✓     | ✓            |
| o3 (medium reasoning)      | 7.5            |      | ✓         | ✓     |              |
| o3 (high reasoning)        | 10             |      | ✓         | ✓     |              |
| o4-mini-medium             | 0.25           | ✓    | ✓         | ✓     |              |
| o4-mini-high               | 0.5            | ✓    | ✓         | ✓     |              |
| Claude 3.5 Sonnet          | 1              | ✓    | ✓         | ✓     | ✓            |
| Claude 3.7 Sonnet          | 1              | ✓    | ✓         | ✓     | ✓            |
| Claude 3.7 Sonnet (Thinking) | 1.25           | ✓    | ✓         | ✓     | ✓            |
| DeepSeek-V3-0324           | 0              |      | ✓         |       |              |
| DeepSeek-R1                | 0.5            |      | ✓         |       |              |
| Gemini 2.0 Flash           | 0.25           | ✓    | ✓         | ✓     |              |
| Gemini 2.5 Flash           | 1              | ✓    | ✓         | ✓     |              |
| Gemini 2.5 Pro             | 1              | ✓    | ✓         |       |              |
| xAI Grok-3                 | 1              |      | ✓         |       |              |
| xAI Grok-3 mini (Thinking) | 0.125          |      | ✓         |       |              |
| Cascade Base ⚡             | 0              | ✓    | ✓         | ✓     |              |

#### Cascade Base Model

All users have unlimited access to **Cascade Base ⚡**, which does NOT consume any prompt credits.

-----

### Windsurf Tab Feature

**Windsurf Tab** has evolved from a simple autocomplete tool into a contextually aware diff-suggestion and navigation engine for writing code.

It is powered by our own models, trained in-house from scratch to optimize for speed and accuracy.

Suggestions are based on the context of your code, terminal, Cascade chat history, your prior actions around the editor, and even your clipboard (must opt in via advanced Settings).

Tab is able to make edits *both before and after* your current cursor position. You can press `esc` to cancel a suggestion.

Suggestions will also disappear if you continue typing or navigating without accepting them.

#### Keyboard Shortcuts for Tab

  * **Accept suggestion:** `tab`
  * **Cancel suggestion:** `esc`
  * **Accept suggestion word-by-word:** `⌘+→` (VS Code), `⌥+⇧+\` (JetBrains)
  * **Next/previous suggestion:** `⌥+]`/`⌥+[`

#### Tab to Jump Functionality

Windsurf can also anticipate your next cursor position and prompt you with a `Tab to Jump` label at a certain line in the editor, allowing you to easily navigate through your file.

If you accept by simply pressing `tab`, then you will be taken to that next position.

#### Tab to Import Functionality

After defining a new dependency to use in a file, just simply hit `tab` to import it at the top of the file once the hint shows. Your cursor will stay in the same position.

#### Tab Settings

Windsurf Tab is split up into two main configurable parts: Autocomplete and Supercomplete.

  * **Autocompletes** typically appear at your cursor.
  * **Supercompletes** appear either in small windows around your cursor, which can suggest both deletions and additions.

Autocomplete and Supercomplete can be toggled on and off. Autocomplete speeds can also be configured between Slow, Default, and Fast modes.

You can also opt-in to using your clipboard as context. This means if you copy something to your clipboard, Windsurf will be able to use it as context.

You can also toggle Tab to Import and Tab to Jump functionalities, and choose whether or not you want to highlight the code after an accepted Tab suggestion.

#### Fill In The Middle (FIM) with Tab

Windsurf Tab can **Fill In The Middle (FIM)**, meaning it can make suggestions while your cursor is in the middle of a line of code.

[Read more about in-line FIM on our blog](https://windsurf.com/blog/inline-fim-code-suggestions).

-----

### Windsurf Command Feature

**Command** generates new or edits existing code via natural language inputs, directly in the editor window.

To invoke Command, press `⌘+I` on Mac or `Ctrl+I` on Windows/Linux.

You can enter a prompt in natural language and hit the Submit button (or `⌘+⏎`/`Ctrl+⏎`) to forward the instruction to the AI.

If you highlight a section of code before invoking Command, then the AI will edit the selection spanned by the highlighted lines. Otherwise, it will generate code at your cursor’s location.

You can accept, reject, or follow-up a generation by clicking the corresponding code lens above the generated diff, or by using the appropriate shortcuts (`Cmd/Ctrl+Enter`/`Cmd/Ctrl+Delete`).

#### Models for Windsurf Command

Command comes with its own set of models that are optimized for current-file edits.

#### Terminal Command with Windsurf Command

You can use Command in the terminal (`Cmd/Ctrl+I`) to generate the proper Command Line Interface (CLI) syntax using prompts in natural language.

#### Best Practices for Using Windsurf Command

Command is great for file-scoped, in-line changes that you can describe as an instruction in natural language. Here are some pointers to keep in mind:

  * The model that powers Command is larger than the one powering autocomplete. It is slower but more capable, and it is trained to be especially good at instruction-following.
  * If you highlight a block of code before invoking Command, it will edit the selection. Otherwise, it will do a pure generation.
  * Using Command effectively can be an art. Simple prompts like “Fix this” or “Refactor” will likely work thanks to Windsurf’s context awareness. A specific prompt like “Write a function that takes two inputs of type `Diffable` and implements the Myers diff algorithm” that contains a clear objective and references to relevant context may help the model even more.

-----

### Code Lenses

#### Explain, Refactor, and Add Docstring Code Lenses

At the top of the text editor, Windsurf exposes *code lenses* on functions and classes.

  * The `Explain` code lens will invoke Cascade, which will simply explain what the function or class does and how it works.
  * The `Refactor` and `Docstring` code lenses in particular will invoke Command.
      * If you click `Refactor`, Windsurf will prompt you with a dropdown of selectable, pre-populated instructions that you can choose from. You can also write your own. This is equivalent to highlighting the function and invoking Command.
      * If you click `Docstring`, Windsurf will generate a docstring for you above the function header. (In Python, the docstring will be correctly generated *underneath* the function header.)

-----

### Smart Paste

This feature allows you to copy code and paste it into a file in your Integrated Development Environment (IDE) written in a different programming language. Use `⌘+⌥+V` (Mac) or `Ctrl+Alt+V` (Windows/Linux) to invoke Smart Paste. Behind the scenes, Windsurf will detect the language of the destination file and use Command to translate the code in your clipboard. Windsurf’s context awareness will try to write it to fit in your code, for example by referencing proper variable names.

Some possible use cases:

  * **Migrating code:** You’re rewriting JavaScript (JS) into TypeScript, or Java into Kotlin.
  * **Pasting from Stack Overflow:** You found a utility function online written in Go, but you’re using Rust.
  * **Learning a new language:** You’re curious about Haskell and want to see what your code would look like if written in it.

-----

### Terminal Integration

#### Using Command in the Terminal

Use our [Command feature](https://docs.windsurf.com/command/overview) modality in the terminal (`Cmd/Ctrl+I`) to generate the proper Command Line Interface (CLI) syntax from prompts in natural language.

#### Sending Terminal Selection to Cascade

Highlight a portion of the stack trace and press `Cmd/Ctrl+L` to send it to Cascade, where you can reference this selection in your next prompt.

#### Auto-Executed Cascade Commands in Terminal

Cascade has the ability to run terminal commands on its own with user permission. However, certain terminal commands can be accepted or rejected automatically through the Allow and Deny lists.

By enabling Auto mode, it will rely on Cascade’s judgement on whether the command requires the user’s permission to be executed. This feature is only available for messages sent with premium models.

##### Turbo Mode

In Turbo mode, Cascade will always execute the command, unless it is in the deny list.

You can toggle this via the Windsurf - Settings panel in the bottom right hand corner of the editor.

##### Allow List for Terminal Commands

An allow list defines a set of terminal commands that will always auto-execute. For example, if you add `git`, then Cascade will always accept `git add -A`.

The setting can be configured via Command Palette → Open Settings (UI) → Search for `windsurf.cascadeCommandsAllowList`.

##### Deny List for Terminal Commands

A deny list defines a set of terminal commands that will never auto-execute. For example, if you add `rm`, then Cascade will always ask for permission to run `rm index.py`.

The setting can be configured via Command Palette → Open Settings (UI) → Search for `windsurf.cascadeCommandsDenyList`.

-----

### Previews (Beta)

Previews in Windsurf allow you to view the local deployment of your app either in the Integrated Development Environment (IDE) or in the browser (optimized for Google Chrome, Arc, and Chromium based browsers) with listeners, allowing you to iterate rapidly by easily sending elements and errors back to Cascade as context.

Previews are opened via tool call, so just ask Cascade to preview your app to get started. Alternatively, you can also click the Web icon in the Cascade toolbar to automatically propagate the natural language prompt to enter the proxy.

#### Sending Elements to Cascade from Previews

In the Preview, you can select and send elements/components and errors directly to Cascade. Simply click on the “Send element” button on the bottom right and then proceed to select the element you want to send.

The selected element will be inserted into your current Cascade prompt as an `@ mention`. You can add as many elements as you want in the prompt.

#### In-IDE Preview Functionality

Windsurf can open up a Preview as a new tab in your editor. This is a simple web view that enables you to view your web app alongside your Cascade panel.

Because these Previews are hosted locally, you can open them in your system browser as well, complete with all the listeners and ability to select and send elements and console errors to Cascade.

#### How to Disable Previews

When you click on the Web icon, it will give you the option to click on “Disable previews”. You can also do this from Windsurf - Settings. This will prevent Cascade from making this tool call.

-----

### AI Commit Messages

Generate git commit messages with a single click. This feature analyzes your code changes and creates meaningful commit messages that describe what you’ve done.

Available with no limits to all paid users.

#### How AI Commit Messages Work

When you’re ready to commit changes:

1.  Stage your files in the Git panel.
2.  Click the sparkle (✨) icon next to the commit message field.
3.  Review the generated message and edit if needed.
4.  Complete your commit.

The AI analyzes your recent code changes and creates a meaningful commit message that describes what you’ve done.

#### Best Practices for AI Commit Messages

For better results:

  * Apply general best practices for commit scope: group together small, meaningful units of changes.
  * Review the message before committing.

#### Limitations of AI Commit Messages

  * Large or complex commits may result in more generic messages.
  * Specialized terminology might not always be captured perfectly.
  * Generated messages are suggestions and may need editing.

#### Privacy Considerations with AI Commit Messages

Your code and commit messages remain private. We don’t store your code changes or use them for training our models.

-----

### Windsurf Advanced Configuration

All advanced configurations can be found in Windsurf Settings which can be accessed by the top right dropdown → Windsurf Settings or Command Palette (`Ctrl/⌘+Shift+P`) → Open Windsurf Settings Page.

#### Enabling Cascade Access to `.gitignore` Files

To provide Cascade with access to files that match patterns in your project’s `.gitignore`, go to your Windsurf Settings and go to “Cascade Gitignore Access”. By default, it is turned off. To provide access, turn it on by clicking the toggle.

#### SSH Support

The usual Secure Shell (SSH) support in VSCode is licensed by Microsoft, so we have implemented our own just for Windsurf. It does require you to have [OpenSSH](https://www.openssh.com/) installed, but otherwise has minimal dependencies, and should “just work” like you’re used to. You can access SSH under `Remote-SSH` in the Command Palette, or via the `Open a Remote Window` button in the bottom left. This extension has worked great for our internal development, but there are some known caveats and bugs:

  * We currently only support SSHing into Linux-based remote hosts.
  * The usual Microsoft “Remote - SSH” extension (and the [open-remote-ssh](https://github.com/jeanp413/open-remote-ssh) extension) will not work—please do not install them, as they conflict with our support.
  * We don’t have all the features of the Microsoft SSH extension right now. We mostly just support the important thing: connecting to a host. If you have feature requests, let us know\!
  * Connecting to a remote host via SSH then accessing a devcontainer on that remote host won’t work like it does in VSCode. (We’re working on it\!) For now, if you want to do this, we recommend instead manually setting up an SSH daemon inside your devcontainer. Here is the set-up which we’ve found to work, but please be careful to make sure it’s right for your use-case.
    1.  Inside the devcontainer, run this once (running multiple times may mess up your `sshd_config`):
        ```bash
        sudo apt-get update && sudo apt-get install -y openssh-server && \
        sudo sed -i 's/#Port 22/Port 2222/' /etc/ssh/sshd_config && \
        sudo sed -i 's/#PermitRootLogin prohibit-password/PermitRootLogin yes/' /etc/ssh/sshd_config && \
        sudo service ssh restart
        ```
    2.  Inside the devcontainer, run this in a terminal you keep alive (e.g., via tmux):
        ```bash
        sudo /usr/sbin/sshd -D -p 2222
        ```
    3.  Then just connect to your remote host via SSH in windsurf, but using the port 2222.
  * SSH agent-forwarding is on by default, and will use Windsurf’s latest connection to that host. If you’re having trouble with it, try reloading the window to refresh the connection.
  * On Windows, you’ll see some `cmd.exe` windows when it asks for your password. This is expected—we’ll get rid of them soon.
  * If you have issues, please first make sure that you can ssh into your remote host using regular `ssh` in a terminal. If the problem persists, include the output from the `Output > Remote SSH (Windsurf)` tab in any bug reports\!

##### Notes on SSH Support

  * SSH + Dev Containers is not currently supported in Windsurf, but we plan to support it in the future.
  * You can only SSH into Linux-based remote hosts at the moment (though you should be able to SSH from all platforms.) We plan to support Windows and macOS in the future.

#### Dev Containers (Beta)

Windsurf has beta support for dev containers for Mac, Windows, and Linux. To use this feature, Docker must be installed on your machine and be accessible from the Windsurf terminal.

If you would like to run a development container locally, you can use the following commands:

1.  `Open Folder in Container`
      * Open a new workspace with a specified `devcontainer.json` file.
2.  `Reopen in Container`
      * Reopen the current workspace in a new container, specifying a `devcontainer.json` file to configure the container.
3.  `Attach to Running Container`
      * If you already have a Docker container running, you can attach a remote server to the container and connect your current workspace to it. If the container does not follow the [Development Container Specification](https://containers.dev/implementors/spec/), we will try our best effort to infer the remote user and set things up accordingly.
4.  `Reopen Folder Locally`
      * If currently connected to a development container, you can disconnect from the container and reopen the current workspace locally.

These will also appear if you click on the `Open a Remote Window` button in the bottom left.

#### Windows Subsystem for Linux (WSL) (Beta)

As of version 1.1.0, Windsurf has beta support for Windows Subsystem for Linux (WSL). You must already have WSL set up and configured on your Windows machine.

You can access WSL by clicking on the `Open a Remote Window` button in the bottom left, or under `Remote-WSL` in the Command Palette.

#### Extension Marketplace Configuration

You can change the marketplace you use to download extensions from. To do this, go to `Windsurf Settings` and modify the Marketplace URL settings under the `General` section.

-----

## Prompt Engineering for Windsurf

This section is for users who may already have some understanding of the use cases and limitations of Large Language Models (LLMs). The better the prompt and context provided to the model, the better the outcome will be.

Similarly with Windsurf, there are best practices for crafting more effective prompts to get the most out of the tool, and get the best quality code possible to help you accelerate your workflows.

### Components of a High-Quality Prompt

  * **Clear objective or outcome:**
      * What are you asking the model to produce?
      * Are you asking the model for a plan? For new code? Is it a refactor?
  * **All relevant context to perform the task(s):**
      * Have you properly used @-Mentions to ensure that the proper context is included?
      * Is there any context that is customer specific that may be unclear to Windsurf?
  * **Necessary constraints:**
      * Are there any specific frameworks, libraries, or languages that must be utilized?
      * Are there any space or time complexity constraints?
      * Are there any security considerations?

### Prompt Examples

  * **Example \#1 (Unit Tests):**

      * **Less Effective:** "Write unit tests for all test cases for an Order Book object."
      * **More Effective:** "Using `@class:unit-testing-module` write unit tests for `@func:src-order-book-add` testing for exceptions thrown when above or below stop loss."

  * **Example \#2 (Refactoring):**

      * **Less Effective:** "Refactor rawDataTransform."
      * **More Effective:** "Refactor `@func:rawDataTransform` by turning the while loop into a for loop and using the same data structure output as `@func:otherDataTransformer`."

  * **Example \#3 (Component Creation):**

      * **Less Effective:** "Create a new Button for the Contact Form."
      * **More Effective:** "Create a new Button component for the `@class:ContactForm` using the style guide in `@repo:frontend-components` that says “Continue”."

<!-- end list -->

